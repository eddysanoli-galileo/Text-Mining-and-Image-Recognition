{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Laboratorio 2: Digit Recognizer\r\n",
    "\r\n",
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import logging \r\n",
    "import os\r\n",
    "\r\n",
    "# Weights and Biases (WandB)\r\n",
    "import wandb \r\n",
    "from wandb.keras import WandbCallback\r\n",
    "\r\n",
    "# Test train split\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# Keras\r\n",
    "# NOTA: No mezclar imports de tensorflow y keras para definiciones de\r\n",
    "# capa u optimizadores. Al compilar el modelo va a dar error.\r\n",
    "import keras\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from keras.optimizers import adam_v2\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Conv2D\r\n",
    "from keras.layers import MaxPool2D\r\n",
    "from keras.layers import Flatten"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Previo (WandB)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Se eliminan los mensajes excesivos de WandB limitándolo a \r\n",
    "# que solo notifique errores que ocurran durante la ejecución.\r\n",
    "logger = logging.getLogger(\"wandb\")\r\n",
    "logger.setLevel(logging.INFO)\r\n",
    "\r\n",
    "# Se le da un nombre al notebook actual dentro de WandB\r\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Laboratorio 2.ipynb\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga y Split de Datos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Se convierte el CSV en un dataframe \r\n",
    "df = pd.read_csv(\"train.csv\")\r\n",
    "\r\n",
    "# Se separan los datos en labels y entradas\r\n",
    "y_data = df[\"label\"].to_numpy() \r\n",
    "X_data = df.iloc[:,1:].to_numpy() \r\n",
    "\r\n",
    "# Se extraen los datos de Test\r\n",
    "# Test: 20% del dataset\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=69)\r\n",
    "\r\n",
    "# Se obtienen los datos de Train y Validación\r\n",
    "# Validation: 10% del dataset\r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=69)\r\n",
    "\r\n",
    "# Los datos se redimensionan para tener una fila por imagen y en\r\n",
    "# las dos dimensiones restantes una imagen de 28x28\r\n",
    "X_train = np.reshape(X_train, (-1, 28, 28, 1))\r\n",
    "X_test = np.reshape(X_test, (-1, 28, 28, 1))\r\n",
    "X_valid = np.reshape(X_valid, (-1, 28, 28, 1))\r\n",
    "\r\n",
    "# Dado que la predicción final se realizará utilizando 10 neuronas softmax, \r\n",
    "# las labels deben ser codificadas utilizando one hot encoding. \r\n",
    "# NOTA: No necesario si se utiliza \"sparse_categorical_crossentropy\" abajo.\r\n",
    "# y_train = to_categorical(y_train)\r\n",
    "# y_test = to_categorical(y_test)\r\n",
    "# y_valid = to_categorical(y_valid)\r\n",
    "\r\n",
    "# Si no se utilizan el OHE anterior, las labels se redimensionan para ser bidimensionales\r\n",
    "y_train = np.reshape(y_train, (-1, 1))\r\n",
    "y_test = np.reshape(y_test, (-1, 1))\r\n",
    "y_valid = np.reshape(y_valid, (-1, 1))\r\n",
    "\r\n",
    "# Se extraen las labels del dataset en string\r\n",
    "labels = list(np.unique(y_train).astype(str))\r\n",
    "\r\n",
    "# Revisar que el redimensionamiento haya sido exitoso\r\n",
    "plt.imshow(X_train[0,:,:,0], cmap=\"gray\")\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Expansion\r\n",
    "\r\n",
    "Normalmente aquí se realizaría una acción para aumentar los datos, pero en este caso se debe ser muy cuidadoso, ya que las imágenes de dígitos no pueden \"flipearse\" o rotarse mucho. La razón para esto es que si rotamos mucho un \"6\", por ejemplo, este comenzará a verse como un \"9\". Para evitar esto, el aumentado de datos debe realizarse de forma conservadora. Las operaciones aplicadas en este caso serían: corte, normalización, rotación leve y zoom. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Generador genera de forma dinámica nuevas muestras con\r\n",
    "# los efectos especificados aplicados.\r\n",
    "datagen = ImageDataGenerator(\r\n",
    "    rescale = 1/255.,\r\n",
    "    shear_range=0.05,\r\n",
    "    zoom_range=0.05,\r\n",
    "    rotation_range=3\r\n",
    ")\r\n",
    "\r\n",
    "# Para utilizar el generador usar el siguiente comando:\r\n",
    "train_gen = datagen.flow(X_train, y_train, batch_size=32)\r\n",
    "test_gen = datagen.flow(X_test, y_test, batch_size=32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo: Red Neuronal Simple\r\n",
    "\r\n",
    "Red neuronal sin cualidades convolucionales. Los pixeles de las imágenes se tratan como listas de valores."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# WandB: 0. Loggearse en Weights and Biases (solo la primera vez que se descarga)\r\n",
    "# wandb.login()\r\n",
    "\r\n",
    "# WandB: 1. Se declara un nuevo run. Se declaran las configuraciones a trackear\r\n",
    "run = wandb.init(project=\"Text_Mining-Lab2\", entity=\"sanoli\",\r\n",
    "                 config={\r\n",
    "                    \"learning_rate\": 0.001, \r\n",
    "                    \"epochs\": 10, \r\n",
    "                    \"batch_size\": 32,  \r\n",
    "                    \"loss_function\": \"sparse_categorical_crossentropy\",  \r\n",
    "                    \"architecture\": \"NN\",  \r\n",
    "                    \"dataset\": \"MNIST\"\r\n",
    "                 })\r\n",
    "\r\n",
    "# NOTAS:\r\n",
    "# - loss_function: Debe ser sparse si las labels no tienen one hot encoding.\r\n",
    "#                  Si no tienen OHE, entonces utilizar \"categorical_crossentropy\"\r\n",
    "\r\n",
    "# Estructura base de la red (una capa detrás de la otra)\r\n",
    "nn = Sequential()\r\n",
    "\r\n",
    "# Inicializador de pesos de la red\r\n",
    "# Se utilizará el de glorot, también conocido como el de Xavier\r\n",
    "initializer = keras.initializers.GlorotNormal()\r\n",
    "\r\n",
    "# Se adicionan capas a la red\r\n",
    "# 1. Flatten: Se crea un solo vector para la imagen de 28x28. None para aceptar cuantas imágenes se necesiten\r\n",
    "# 2. Dense: Capas densas de dimensiones en decremento para \"comprimir\" la información\r\n",
    "# 3. Dense: 10 neuronas de salida para clasificación multiclase (softmax). \r\n",
    "nn.add(Flatten(input_shape=(28, 28, 1)))\r\n",
    "nn.add(Dense(units=256, activation=\"relu\", kernel_initializer=initializer))\r\n",
    "nn.add(Dense(units=128, activation=\"relu\", kernel_initializer=initializer))\r\n",
    "nn.add(Dense(units=64, activation=\"relu\", kernel_initializer=initializer))\r\n",
    "nn.add(Dense(units=10, activation=\"softmax\"))\r\n",
    "\r\n",
    "# WandB: 2. Guarda los inputs e hiperparámetros del modelo\r\n",
    "config = wandb.config\r\n",
    "\r\n",
    "# Se selecciona el optimizador\r\n",
    "optimizer = adam_v2.Adam(learning_rate=config.learning_rate)\r\n",
    "\r\n",
    "# Se compila el modelo\r\n",
    "nn.compile(optimizer=optimizer, loss=config.loss_function, metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "# Se entrena el modelo \r\n",
    "nn.fit(X_train, y_train, epochs=config.epochs, batch_size=config.batch_size, validation_data=(X_valid, y_valid), \r\n",
    "       callbacks=[\r\n",
    "            # Se envían datos a weights and biases\r\n",
    "            WandbCallback(\r\n",
    "                data_type=\"image\",                      # Se generan imágenes en el reporte\r\n",
    "                monitor=\"accuracy\",                     # Monitorea el accuracy como métrica\r\n",
    "                mode=\"max\",                             # Trackea aumentos en accuracy\r\n",
    "                save_model=True,                        # Guardar modelo cuando se alcanza un nuevo máximo en accuracy\r\n",
    "                validation_data=(X_valid, y_valid),     # WandB hace predicciones a medio proceso y las despliega en el dashboard\r\n",
    "                labels=labels,                          # Se declaran las labels que se van a predecir\r\n",
    "                predictions=10                          # Número de predicciones a generar\r\n",
    "            ),          \r\n",
    "       ])\r\n",
    "\r\n",
    "# Se mide la precisión con set pruebas\r\n",
    "loss, accuracy = nn.evaluate(X_test, y_test)\r\n",
    "print(f\"Test Error Rate: {round((1-accuracy)*100, 2)}\")\r\n",
    "\r\n",
    "# Se loguean los resultados en WandB\r\n",
    "wandb.log({\"Test Error Rate\" : round((1-accuracy)*100, 2)})\r\n",
    "run.join()\r\n",
    "\r\n",
    "# Se finaliza el \"run\" de WandB\r\n",
    "run.finish()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Finishing last run (ID:3j8wbwcu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6796<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d0d731ca95c4c7896d268e1054c7cb7"
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: ERROR Control-C detected -- Run data was not synced\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3j8wbwcu). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">usual-firefly-17</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sanoli/Text_Mining-Lab2\" target=\"_blank\">https://wandb.ai/sanoli/Text_Mining-Lab2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sanoli/Text_Mining-Lab2/runs/20dpy665\" target=\"_blank\">https://wandb.ai/sanoli/Text_Mining-Lab2/runs/20dpy665</a><br/>\n",
       "                Run data is saved locally in <code>e:\\Archivos\\Educación\\Posgrado\\Universidad Galileo (UG)\\Trimestre III\\Text Mining & Image Recognition\\Laboratorios\\Laboratorio 2\\wandb\\run-20210911_231417-20dpy665</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "  1/945 [..............................] - ETA: 8:09 - loss: 127.8252 - accuracy: 0.0625WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0057s). Check your callbacks.\n",
      "945/945 [==============================] - 4s 4ms/step - loss: 1.6834 - accuracy: 0.8586 - val_loss: 0.4581 - val_accuracy: 0.9089\n",
      "Epoch 2/10\n",
      "945/945 [==============================] - 4s 4ms/step - loss: 0.2878 - accuracy: 0.9319 - val_loss: 0.3321 - val_accuracy: 0.9271\n",
      "Epoch 3/10\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1953 - accuracy: 0.9485 - val_loss: 0.2797 - val_accuracy: 0.9351\n",
      "Epoch 4/10\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1746 - accuracy: 0.9529 - val_loss: 0.2299 - val_accuracy: 0.9464\n",
      "Epoch 5/10\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1455 - accuracy: 0.9607 - val_loss: 0.2171 - val_accuracy: 0.9417\n",
      "Epoch 6/10\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1269 - accuracy: 0.9649 - val_loss: 0.2902 - val_accuracy: 0.9420\n",
      "Epoch 7/10\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.1242 - accuracy: 0.9650 - val_loss: 0.1968 - val_accuracy: 0.9527\n",
      "Epoch 8/10\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.0862 - accuracy: 0.9746 - val_loss: 0.1871 - val_accuracy: 0.9563\n",
      "Epoch 9/10\n",
      "945/945 [==============================] - 2s 3ms/step - loss: 0.0977 - accuracy: 0.9738 - val_loss: 0.1959 - val_accuracy: 0.9533\n",
      "Epoch 10/10\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.9773 - val_loss: 0.1777 - val_accuracy: 0.9577\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 0.1947 - accuracy: 0.9571\n",
      "Test Error Rate: 4.29\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 15920<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "193cb2c83a384fd08dce98340932c689"
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.84MB of 2.84MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>e:\\Archivos\\Educación\\Posgrado\\Universidad Galileo (UG)\\Trimestre III\\Text Mining & Image Recognition\\Laboratorios\\Laboratorio 2\\wandb\\run-20210911_231417-20dpy665\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>e:\\Archivos\\Educación\\Posgrado\\Universidad Galileo (UG)\\Trimestre III\\Text Mining & Image Recognition\\Laboratorios\\Laboratorio 2\\wandb\\run-20210911_231417-20dpy665\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.08212</td></tr><tr><td>accuracy</td><td>0.97728</td></tr><tr><td>val_loss</td><td>0.17767</td></tr><tr><td>val_accuracy</td><td>0.95774</td></tr><tr><td>_runtime</td><td>39</td></tr><tr><td>_timestamp</td><td>1631423773</td></tr><tr><td>_step</td><td>10</td></tr><tr><td>best_accuracy</td><td>0.97728</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>Test Error Rate</td><td>4.29</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▅▆▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▄▂▂▄▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▆▇█▇█</td></tr><tr><td>_runtime</td><td>▁▂▃▄▄▅▆▆▇██</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▄▅▆▆▇██</td></tr><tr><td>_step</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>Test Error Rate</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 101 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">usual-firefly-17</strong>: <a href=\"https://wandb.ai/sanoli/Text_Mining-Lab2/runs/20dpy665\" target=\"_blank\">https://wandb.ai/sanoli/Text_Mining-Lab2/runs/20dpy665</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo: Red Neuronal Convolucional\r\n",
    "\r\n",
    "Red neuronal convolucional. Las imágenes se alimentan directamente a la red en sus dimensiones originales."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# WandB: 1. Se declara un nuevo run. Se declaran las configuraciones a trackear\r\n",
    "run = wandb.init(project=\"Text_Mining-Lab2\", entity=\"sanoli\",\r\n",
    "                 config={\r\n",
    "                    \"learning_rate\": 0.001, \r\n",
    "                    \"epochs\": 10, \r\n",
    "                    \"batch_size\": 32,  \r\n",
    "                    \"loss_function\": \"sparse_categorical_crossentropy\",  \r\n",
    "                    \"architecture\": \"CNN\",  \r\n",
    "                    \"dataset\": \"MNIST\"\r\n",
    "                 })\r\n",
    "\r\n",
    "# NOTAS:\r\n",
    "# - loss_function: Debe ser sparse si las labels no tienen one hot encoding.\r\n",
    "#                  Si no tienen OHE, entonces utilizar \"categorical_crossentropy\"\r\n",
    "\r\n",
    "# Estructura base de la red (una capa detrás de la otra)\r\n",
    "cnn = Sequential()\r\n",
    "\r\n",
    "# Inicializador de pesos de la red\r\n",
    "# Se utilizará el de glorot, también conocido como el de Xavier\r\n",
    "initializer = keras.initializers.GlorotNormal()\r\n",
    "\r\n",
    "# Se adicionan capas a la red\r\n",
    "# 1. Conv2D + MaxPool2D: Se convoluciona la imagen y se le aplica max pooling para \"comprimir\" información\r\n",
    "# 2. Flatten: Se aplanan las matrices bidimensionales resultantes de la etapa convolucional\r\n",
    "# 2. Dense: Capas densas de dimensiones en decremento para \"comprimir\" la información\r\n",
    "# 3. Dense: 10 neuronas de salida para clasificación multiclase (softmax). \r\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(28,28,1), activation=\"relu\"))\r\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\r\n",
    "cnn.add(Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\"))\r\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\r\n",
    "cnn.add(Flatten())\r\n",
    "cnn.add(Dense(units=256, activation=\"relu\", kernel_initializer=initializer))\r\n",
    "cnn.add(Dense(units=128, activation=\"relu\", kernel_initializer=initializer))\r\n",
    "cnn.add(Dense(units=64, activation=\"relu\", kernel_initializer=initializer))\r\n",
    "cnn.add(Dense(units=10, activation=\"softmax\"))\r\n",
    "\r\n",
    "# WandB: 2. Guarda los inputs e hiperparámetros del modelo\r\n",
    "config = wandb.config\r\n",
    "\r\n",
    "# Se selecciona el optimizador\r\n",
    "optimizer = adam_v2.Adam(learning_rate=config.learning_rate)\r\n",
    "\r\n",
    "# Se compila el modelo\r\n",
    "cnn.compile(optimizer=optimizer, loss=config.loss_function, metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "# Se entrena el modelo \r\n",
    "cnn.fit(X_train, y_train, epochs=config.epochs, batch_size=config.batch_size, validation_data=(X_valid, y_valid), \r\n",
    "       callbacks=[\r\n",
    "            # Se envían datos a weights and biases\r\n",
    "            WandbCallback(\r\n",
    "                data_type=\"image\",                      # Se generan imágenes en el reporte\r\n",
    "                monitor=\"accuracy\",                     # Monitorea el accuracy como métrica\r\n",
    "                mode=\"max\",                             # Trackea aumentos en accuracy\r\n",
    "                save_model=True,                        # Guardar modelo cuando se alcanza un nuevo máximo en accuracy\r\n",
    "                validation_data=(X_valid, y_valid),     # WandB hace predicciones a medio proceso y las despliega en el dashboard\r\n",
    "                labels=labels,                          # Se declaran las labels que se van a predecir\r\n",
    "                predictions=10                          # Número de predicciones a generar\r\n",
    "            ),          \r\n",
    "       ])\r\n",
    "\r\n",
    "# Se mide la precisión con set pruebas\r\n",
    "loss, accuracy = cnn.evaluate(X_test, y_test)\r\n",
    "print(f\"Test Error Rate: {round((1-accuracy)*100, 2)}\")\r\n",
    "\r\n",
    "# Se loguean los resultados en WandB\r\n",
    "wandb.log({\"Test Error Rate\" : round((1-accuracy)*100, 2)})\r\n",
    "run.join()\r\n",
    "\r\n",
    "# Se finaliza el \"run\" de WandB\r\n",
    "run.finish()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">celestial-violet-19</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sanoli/Text_Mining-Lab2\" target=\"_blank\">https://wandb.ai/sanoli/Text_Mining-Lab2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sanoli/Text_Mining-Lab2/runs/3da95o87\" target=\"_blank\">https://wandb.ai/sanoli/Text_Mining-Lab2/runs/3da95o87</a><br/>\n",
       "                Run data is saved locally in <code>e:\\Archivos\\Educación\\Posgrado\\Universidad Galileo (UG)\\Trimestre III\\Text Mining & Image Recognition\\Laboratorios\\Laboratorio 2\\wandb\\run-20210911_233611-3da95o87</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "945/945 [==============================] - 15s 15ms/step - loss: 0.3756 - accuracy: 0.9172 - val_loss: 0.1574 - val_accuracy: 0.9476\n",
      "Epoch 2/10\n",
      "945/945 [==============================] - 15s 16ms/step - loss: 0.0943 - accuracy: 0.9712 - val_loss: 0.1245 - val_accuracy: 0.9625\n",
      "Epoch 3/10\n",
      "945/945 [==============================] - 14s 14ms/step - loss: 0.0700 - accuracy: 0.9788 - val_loss: 0.0942 - val_accuracy: 0.9735\n",
      "Epoch 4/10\n",
      "945/945 [==============================] - 14s 15ms/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.1302 - val_accuracy: 0.9643\n",
      "Epoch 5/10\n",
      "945/945 [==============================] - 14s 15ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.0666 - val_accuracy: 0.9786\n",
      "Epoch 6/10\n",
      "945/945 [==============================] - 14s 15ms/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.0800 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "945/945 [==============================] - 14s 15ms/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.0722 - val_accuracy: 0.9827\n",
      "Epoch 8/10\n",
      "945/945 [==============================] - 14s 15ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "945/945 [==============================] - 14s 15ms/step - loss: 0.0328 - accuracy: 0.9907 - val_loss: 0.0635 - val_accuracy: 0.9839\n",
      "Epoch 10/10\n",
      "945/945 [==============================] - 14s 15ms/step - loss: 0.0286 - accuracy: 0.9921 - val_loss: 0.0951 - val_accuracy: 0.9777\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 0.0889 - accuracy: 0.9824\n",
      "Test Error Rate: 1.76\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11168<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "853c08694c664f59948cb36c79bcb48f"
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1.80MB of 1.80MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>e:\\Archivos\\Educación\\Posgrado\\Universidad Galileo (UG)\\Trimestre III\\Text Mining & Image Recognition\\Laboratorios\\Laboratorio 2\\wandb\\run-20210911_233611-3da95o87\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>e:\\Archivos\\Educación\\Posgrado\\Universidad Galileo (UG)\\Trimestre III\\Text Mining & Image Recognition\\Laboratorios\\Laboratorio 2\\wandb\\run-20210911_233611-3da95o87\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.02859</td></tr><tr><td>accuracy</td><td>0.99213</td></tr><tr><td>val_loss</td><td>0.09511</td></tr><tr><td>val_accuracy</td><td>0.97768</td></tr><tr><td>_runtime</td><td>150</td></tr><tr><td>_timestamp</td><td>1631425121</td></tr><tr><td>_step</td><td>10</td></tr><tr><td>best_accuracy</td><td>0.99213</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>Test Error Rate</td><td>1.76</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▂▂▂▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▃▆▁▂▂▃▁▃</td></tr><tr><td>val_accuracy</td><td>▁▄▆▄▇▇█▇█▇</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇██</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇██</td></tr><tr><td>_step</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>Test Error Rate</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 101 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">celestial-violet-19</strong>: <a href=\"https://wandb.ai/sanoli/Text_Mining-Lab2/runs/3da95o87\" target=\"_blank\">https://wandb.ai/sanoli/Text_Mining-Lab2/runs/3da95o87</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusiones\r\n",
    "\r\n",
    "Al finalizar el proceso de entrenamiento de ambos tipos de red neuronal (NN y CNN) se llegó a determinar que aunque ambas contaban con una precisión muy alta, la red neuronal convolucional consiguió obtener una ventaja ligeramente mayor por sobre la red neuronal tradicional.\r\n",
    "\r\n",
    "<img src=\"imgs/test_error_rate.png\" alt=\"test_error\" width=\"500\">\r\n",
    "<img src=\"imgs/val_accuracy.png\" alt=\"test_error\" width=\"500\">\r\n",
    "\r\n",
    "Como se puede observar en los gráficos anteriores, la corrida que fue realizada con la red convolucional (de color rojo), obtuvo no solo una precisión de evaluación más alta (val_accuracy) a lo largo de todo el entrenamiento, si no que también obtuvo un error de precisión (Test Error Rate) ligeramente más bajo a comparación de todas las demás corridas. Dado que las demás corridas corresponden al modelo con redes neuronales tradicionales, se puede establecer que las redes convolucionales obtuvieron resultados buenos, pero nunca tan buenos como las redes convolucionales. Curiosamente, el punteo de evaluación y de entrenamiento en ambas redes, siempre se encontraban súmamente cercanos entre si, lo que implica que probablemente se le podría agregar un poco más de capacidad al modelo y este podrá alcanzar resultados mejores. Para verificar esto, se agregó una capa adicional al modelo convolucional y se observaron los resultados. Al analizar los resultados (barra verde o \"celestial-violet-19\") se llegó a evidenciar que efectivamente, el porcentaje de error se había reducido ligeramente.\r\n",
    "\r\n",
    "<img src=\"imgs/test_error_rate2.png\" alt=\"test_error\" width=\"500\">\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "658dc12c475a3a8caebf03b24f414cffa2901ebd330ffd26b9c22f028a90850c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}